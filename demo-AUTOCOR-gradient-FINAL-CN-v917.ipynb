{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f355a9b4-8456-4fec-b304-9304a34d00e1",
   "metadata": {},
   "source": [
    "# Analysis for Correlation: Correlation Heat Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d520-96d0-48ac-a8e8-bb2e91e1828b",
   "metadata": {},
   "source": [
    "# 实验数据自动相关性分析（快速上手）\n",
    "# —— 仅需 5 步 ——\n",
    "\n",
    "\n",
    "1.  准备数据（Excel）\n",
    "   - 表头全部用英文/数字/下划线（ASCII），不要中文或全角。\n",
    "   - 第一列名必须是 index，行值用 I/II + CK/Cat/Glu/Gly（如 I-CK、II-Glu）。\n",
    "   - 其余列都是数值型结果变量（可增减）。\n",
    "   - 保存为 .xlsx 或 .xls\n",
    "\n",
    "---\n",
    "\n",
    "2. 环境准备\n",
    "- 安装 Python\n",
    "- cmd里: \n",
    "    - `pip install jupyter`\n",
    "    - `pip install pandas matplotlib networkx openpyxl ipywidgets`\n",
    "    - `jupyter lab` \n",
    "- 输入 `jupyter lab` 之后，jupynotebook 就被打开\n",
    "- 点左上角加号 notebook创建新的notebook，或者文件-导入我这个notebook\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "3. 打开并配置脚本顶部参数（红色“只需修改本段”那块）\n",
    "- MY_EXCEL_FILE = \"你的数据.xlsx\"\n",
    "- SHOW_CORRELATIONS_ABOVE = 0.30      # 只显示 |r| ≥ 阈值 的连线\n",
    "- TOP_CORRELATIONS_PER_TREATMENT = 6  # 每个处理保留前 k 个强相关\n",
    "- MY_ANALYSIS_TITLE = \"Treatment–Outcome Correlations\"  # 图标题（英文保留）\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "4. 运行程序\n",
    "- 终端：python your_script.py\n",
    "- Jupyter：运行整份 Notebook\n",
    " - 终端/输出区会提示进度；若找不到文件，请检查路径与扩展名。\n",
    "\n",
    "---\n",
    "\n",
    "5. 看结果 & 出图\n",
    " - 会在同目录生成：<你的数据>_correlation_results.csv\n",
    " - 在 Jupyter 底部有两个中文控制面板：\n",
    "     • “热图控制”：改配色/尺寸/角度 → 点“重绘热图”；点“保存热图 PNG”导出。\n",
    "     • “网络图微调”：改标签距离/圆半径/阈值/Top 数/图例位置 → 点“重绘”；点“保存网络图 PNG”导出。\n",
    " - 图表字体固定为 Times New Roman；标题/图例保持英文，界面与提示为中文。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcad433-78d4-4ad1-bd11-d70576a1a45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔════════════════════════════════════════════════════════════════════╗\n",
      "║   📊 欢迎使用相关性分析工具                                        ║\n",
      "╚════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "\n",
      "上传前请按下述英文表头整理（仅 ASCII），示例：\n",
      "\n",
      "index | AlkaliN | AvailP | AvailK | SOM  | pH  | AvailZn | Yield\n",
      "------+---------+--------+--------+------+-----+---------+-------\n",
      "Zn0   |  98.4   |  19.4  |  172.4 | 14.8 | 6.11|  6.74   | 10257.1\n",
      "LZn   |  65.7   |  33.0  |  189.7 | 15.0 | 5.34|  7.96   | 12426.8\n",
      "HZn   |  85.5   |  20.7  |  176.7 | 13.8 | 5.12|  8.05   | 12522.5\n",
      "\n",
      "上传规范：\n",
      "- 第一列表头必须为 index；行值仅能是 Zn0、LZn、HZn（锌的 3 个水平）。\n",
      "- 其它列为数值型结果变量（英文/数字/下划线，勿用中文或全角字符）。\n",
      "- 小数使用点号 .（如 7.83），不要逗号。\n",
      "- 可自行增删结果列；顺序不限。\n",
      "- 保存为 .xlsx/.xls 后上传。\n",
      "\n",
      "\n",
      "📂 使用的 Excel 文件: gao_pca.xlsx\n",
      "🎯 |r| 阈值: 0.3\n",
      "🔝 每个处理的 Top 数: 6\n",
      "\n",
      "================================================================================\n",
      "   开始自动相关性分析\n",
      "================================================================================\n",
      "\n",
      "✅ 已从文件读取 3 行： 'gao_pca.xlsx'\n",
      "\n",
      "🧹 正在清理数据…\n",
      "\n",
      "🔎 检测到可能的单因子标签： Zn0, LZn, HZn\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "是否启用【单因子梯度】模式？(y/N)： \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧩 检测到单因子梯度设计： ['HZn', 'LZn', 'Zn0']\n",
      "\n",
      "🔍 （索引解析）自动识别的设计：\n",
      "  📦 原料/材料: []\n",
      "  🧪 添加剂: []\n",
      "  📊 结果变量: ['Soil organic matter', 'Available Zn', 'Corn yield', 'FI', 'BIX'] ...\n",
      "\n",
      "✅ 设计矩阵：3 个样本 × 3 个处理\n",
      "\n",
      "📈 正在计算与 17 个结果变量的相关系数…\n",
      "✅ 相关计算完成。\n",
      "\n",
      "💾 结果已保存至 : gao_pca_correlation_results.csv\n",
      "\n",
      "================================================================================\n",
      "   Top 相关结果\n",
      "================================================================================\n",
      "\n",
      "🔍 显著相关（|r| > 0.3）：\n",
      "----------------------------------------------------------------------\n",
      "  Zn0                            → CHA             r = -1.000 ↓\n",
      "  Zn0                            → Corn yield      r = -0.999 ↓\n",
      "  Zn0                            → Available Zn    r = -0.998 ↓\n",
      "  Zn0                            → O/C ratio of HA r = +0.996 ↑\n",
      "  HZn                            → Exothermic ratio of high to moderate temperature r = +0.993 ↑\n",
      "  Zn0                            → CWSS            r = -0.991 ↓\n",
      "  HZn                            → Soil organic matter r = -0.988 ↓\n",
      "  HZn                            → CHU             r = -0.987 ↓\n",
      "  HZn                            → C/N ratio of HA r = -0.987 ↓\n",
      "  LZn                            → FI              r = -0.985 ↓\n",
      "  Zn0                            → HIX             r = -0.985 ↓\n",
      "  HZn                            → CHE             r = +0.945 ↑\n",
      "  LZn                            → BIX             r = -0.945 ↓\n",
      "  LZn                            → H/C ratio of HA r = -0.934 ↓\n",
      "  Zn0                            → E4/E6 of HA alkali extract r = -0.929 ↓\n",
      "  HZn                            → CHA/CFA         r = -0.923 ↓\n",
      "  LZn                            → Aliphatic C/Aromatic C r = -0.880 ↓\n",
      "  Zn0                            → Aliphatic C/Aromatic C r = +0.851 ↑\n",
      "  LZn                            → CHA/CFA         r = +0.795 ↑\n",
      "  LZn                            → E4/E6 of HA alkali extract r = +0.786 ↑\n",
      "\n",
      "  ... 25 more.\n",
      "\n",
      "================================================================================\n",
      "   ✨ 分析完成！ ✨\n",
      "================================================================================\n",
      "\n",
      " 📁 结果已保存至 : gao_pca_correlation_results.csv\n",
      " 📊 数据文件: gao_pca.xlsx\n",
      " 🧪 设计规模: 0 × 0\n",
      " 📈 结果变量数量: 17\n",
      "\n",
      "🧩 热图控制\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d791984f95f4f20af6a4a78c3e9d31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>热图颜色</b>'), HBox(children=(ColorPicker(value='#01756d', description='c1（负向，-）', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5025164142141429ac4b18dc42bf477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎛️ 使用下面的滑块微调网络图布局。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6719bd1ef424a94bf2c3780cac66c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=0.15, continuous_update=False, description='标签间距', max=0.8, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fce0e0b4294750a5d4ad3eb042c789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════════════════╗\n",
    "║        实验数据自动相关性分析（Automatic Correlation Analysis）                ║\n",
    "║        版本: 2.0 - 学生友好版                                                ║\n",
    "╚════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# 🔴 只需修改本段（学生看到的标题等）\n",
    "# =============================================================================\n",
    "MY_EXCEL_FILE = \"gao_pca.xlsx\"\n",
    "SHOW_CORRELATIONS_ABOVE = 0.30\n",
    "TOP_CORRELATIONS_PER_TREATMENT = 6\n",
    "MY_ANALYSIS_TITLE = \"Treatment–Outcome Correlations\"\n",
    "# 单因子“梯度”模式（可选）\n",
    "FACTOR_HINT = None        # 例如 \"Zn\" / \"Cu\"；None 自动识别\n",
    "LEVEL_ORDER = None        # 强制顺序，例如 [\"Zn0\",\"LZn\",\"HZn\"]；None 自动排序\n",
    "MAX_LEVELS  = 50          # index 唯一水平上限（防误判）\n",
    "INTERACTIVE_LEVEL_PROMPT = True   # 🆕 总是先问用户是否使用单因子梯度，并逐项确认顺序\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 🌏 Language / 语言\n",
    "# =============================================================================\n",
    "LOCALE = \"zh\"   # \"zh\" for Chinese, \"en\" for English\n",
    "\n",
    "# Only the widgets/console are Chinese; plots stay English\n",
    "UI_LOCALE = \"zh\"          # widgets + console\n",
    "PLOTS_IN_CHINESE = False  # plots: keep English text\n",
    "def t_ui(key, **kw):  # use this for widgets/prints\n",
    "    return TR.get(UI_LOCALE, TR[\"zh\"]).get(key, key).format(**kw)\n",
    "def t_plot(key, **kw):    # use this for plot text\n",
    "    return (TR[\"zh\"] if PLOTS_IN_CHINESE else TR[\"en\"]).get(key, key).format(**kw)\n",
    "\n",
    "\n",
    "TR = {\n",
    "    \"en\": {\n",
    "        \"welcome_banner\": \"\\n╔════════════════════════════════════════════════════════════════════╗\\n║   📊 WELCOME TO THE CORRELATION ANALYSIS TOOL                     ║\\n╚════════════════════════════════════════════════════════════════════╝\\n\",\n",
    "        \"sample_title\": \"Expected Excel/CSV format (first rows look like this):\",\n",
    "        \"legend_block\": \"Legend:\\n- First 2 columns (SMS, PM; or SMS1, SMS2) = compost/material indicators (binary).\\n- Next 4 columns (CK, Cat, Glu, Gly) = additives (binary).\\n- Remaining columns = outcome variables (numeric measurements).\\n\",\n",
    "        \"using_file\": \"Using Excel file\",\n",
    "        \"thr\": \"|r| threshold\",\n",
    "        \"topk\": \"Top per treatment\",\n",
    "        \"loaded_rows\": \"Loaded {n} rows from\",\n",
    "        \"cleaning\": \"Cleaning data...\",\n",
    "        \"removed_cols\": \"Removed {n} problematic column(s).\",\n",
    "        \"cant_find\": \"ERROR: Cannot find the file\",\n",
    "        \"current_folder\": \"Current folder\",\n",
    "        \"excel_here\": \"Excel files here\",\n",
    "        \"built_from_index\": \"Built design from index:\",\n",
    "        \"materials\": \"Materials\",\n",
    "        \"additives\": \"Additives\",\n",
    "        \"outcomes\": \"Outcomes\",\n",
    "        \"ask_I\": \"Enter material name for Treatment I [For example: {default_I}]: \",\n",
    "        \"ask_II\": \"Enter material name for Treatment II [For example: {default_II}]: \",\n",
    "        \"auto_detected\": \"Auto-detected design (from index):\",\n",
    "        \"fallback_detected\": \"Auto-detected design:\",\n",
    "        \"no_numeric\": \"ERROR: No numeric outcome columns detected.\",\n",
    "        \"found_treatments\": \"Found {k} unique treatment combinations:\",\n",
    "        \"design_shape\": \"Design matrix: {n} samples × {p} treatments\",\n",
    "        \"calc_corr\": \"Calculating correlations with {m} outcomes...\",\n",
    "        \"calc_done\": \"Correlations calculated.\",\n",
    "        \"saved_to\": \"Results saved to\",\n",
    "        \"hm_creating\": \"Creating heatmap...\",\n",
    "        \"hm_done\": \"Heatmap displayed.\",\n",
    "        \"net_creating\": \"Creating circular network visualization...\",\n",
    "        \"no_edges\": \"No correlations found above {thr}\",\n",
    "        \"net_done\": \"Pie network created with {E} edges.\",\n",
    "        \"sig_header\": \"Significant correlations (|r| > {thr}):\",\n",
    "        \"none\": \"None.\",\n",
    "        \"start\": \"STARTING AUTOMATED CORRELATION ANALYSIS\",\n",
    "        \"viz_header\": \"CREATING VISUALIZATIONS\",\n",
    "        \"viz1\": \"VISUALIZATION 1: Correlation Heatmap\",\n",
    "        \"viz2\": \"VISUALIZATION 2: Circular Network\",\n",
    "        \"top_header\": \"TOP CORRELATIONS\",\n",
    "        \"complete\": \"ANALYSIS COMPLETE!\",\n",
    "        \"summary_data\": \"Data analyzed\",\n",
    "        \"summary_design\": \"Design\",\n",
    "        \"summary_outcomes\": \"Outcomes analyzed\",\n",
    "        \"heatmap_controls\": \"Heatmap controls\",\n",
    "        \"heatmap_colors\": \"Heatmap colors\",\n",
    "        \"c1\": \"c1 (neg, -)\",\n",
    "        \"c3\": \"c3 (mid)\",\n",
    "        \"c5\": \"c5 (pos, +)\",\n",
    "        \"size\": \"Size\",\n",
    "        \"use_explicit\": \"Use explicit size\",\n",
    "        \"width_in\": \"Width (in)\",\n",
    "        \"height_in\": \"Height (in)\",\n",
    "        \"display\": \"Display\",\n",
    "        \"annotate\": \"Annotate cells\",\n",
    "        \"center0\": \"Center at 0 (±vmax)\",\n",
    "        \"xrot\": \"X rotation\",\n",
    "        \"vmax_abs\": \"vmax_abs (optional)\",\n",
    "        \"grid_minor\": \"Show minor grid\",\n",
    "        \"redraw_heatmap\": \"Redraw Heatmap\",\n",
    "        \"save\": \"Save\",\n",
    "        \"filename\": \"Filename\",\n",
    "        \"dpi\": \"DPI\",\n",
    "        \"transparent\": \"Transparent\",\n",
    "        \"save_hm\": \"Save Heatmap PNG\",\n",
    "        \"drawing_hm\": \"Drawing correlation heatmap...\",\n",
    "        \"net_controls_tip\": \"Use the controls below to fine-tune the network layout.\",\n",
    "        \"shown\": \"Heatmap shown.\",\n",
    "        \"network_tuning\": \"Network tuning\",\n",
    "        \"label_dist\": \"Label distance\",\n",
    "        \"circle_radius\": \"Circle radius\",\n",
    "        \"edge_curv\": \"Edge curvature\",\n",
    "        \"r_thresh\": \"|r| threshold\",\n",
    "        \"top_per_trt\": \"Top per trt\",\n",
    "        \"legend_loc\": \"Legend loc\",\n",
    "        \"legend_cols\": \"legend cols\",\n",
    "        \"legend_pad\": \"legend pad\",\n",
    "        \"title_pad_frac\": \"title pad (frac)\",\n",
    "        \"redraw\": \"Redraw\",\n",
    "        \"save_net\": \"Save Network PNG\",\n",
    "        \"drawing_net\": \"Drawing circular network...\",\n",
    "        \"net_title\": \"Circular Network (|r| ≥ {thr}, top {k}/treatment)\",\n",
    "        \"legend_trt\": \"Treatment\",\n",
    "        \"legend_out\": \"Outcome\",\n",
    "        \"legend_pos\": \"Positive correlation\",\n",
    "        \"legend_neg\": \"Negative correlation\",\n",
    "        \"colorbar\": \"Pearson Correlation\",\n",
    "    },\n",
    "    \"zh\": {\n",
    "        \"welcome_banner\": \"\\n╔════════════════════════════════════════════════════════════════════╗\\n║   📊 欢迎使用相关性分析工具                                        ║\\n╚════════════════════════════════════════════════════════════════════╝\\n\",\n",
    "        \"sample_title\": \"期望的 Excel/CSV 格式（前几行示例）：\",\n",
    "        \"legend_block\": \"说明：\\n- 前两列（如 SMS、PM 或 SMS1、SMS2）= 原料/材料指示（0/1）。\\n- 接下来的四列（CK、Cat、Glu、Gly）= 添加剂指示（0/1）。\\n- 其余列 = 各种测量的数值型结果变量。\\n\",\n",
    "        \"using_file\": \"使用的 Excel 文件\",\n",
    "        \"thr\": \"|r| 阈值\",\n",
    "        \"topk\": \"每个处理的 Top 数\",\n",
    "        \"loaded_rows\": \"已从文件读取 {n} 行：\",\n",
    "        \"cleaning\": \"正在清理数据…\",\n",
    "        \"removed_cols\": \"已移除 {n} 个存在问题的列。\",\n",
    "        \"cant_find\": \"错误：找不到文件\",\n",
    "        \"current_folder\": \"当前文件夹\",\n",
    "        \"excel_here\": \"此处的 Excel 文件\",\n",
    "        \"built_from_index\": \"已根据索引/标签列构建设计矩阵：\",\n",
    "        \"materials\": \"原料/材料\",\n",
    "        \"additives\": \"添加剂\",\n",
    "        \"outcomes\": \"结果变量\",\n",
    "        \"ask_I\": \"请输入“处理 I”的材料名称（例如 {default_I}）：\",\n",
    "        \"ask_II\": \"请输入“处理 II”的材料名称（例如 {default_II}）：\",\n",
    "        \"auto_detected\": \"（索引解析）自动识别的设计：\",\n",
    "        \"fallback_detected\": \"自动识别的设计：\",\n",
    "        \"no_numeric\": \"错误：未检测到数值型结果列。\",\n",
    "        \"found_treatments\": \"共发现 {k} 种处理组合：\",\n",
    "        \"design_shape\": \"设计矩阵：{n} 个样本 × {p} 个处理\",\n",
    "        \"calc_corr\": \"正在计算与 {m} 个结果变量的相关系数…\",\n",
    "        \"calc_done\": \"相关计算完成。\",\n",
    "        \"saved_to\": \"结果已保存至\",\n",
    "        \"hm_creating\": \"正在绘制热图…\",\n",
    "        \"hm_done\": \"热图已显示。\",\n",
    "        \"no_edges\": \"没有相关系数高于阈值 {thr}\",\n",
    "        \"net_done\": \"网络图已生成，连边数 {E}。\",\n",
    "        \"sig_header\": \"显著相关（|r| > {thr}）：\",\n",
    "        \"none\": \"无。\",\n",
    "        \"start\": \"开始自动相关性分析\",\n",
    "        \"viz_header\": \"开始创建可视化\",\n",
    "        \"viz1\": \"可视化 1：相关性热图\",\n",
    "        \"viz2\": \"可视化 2：环形网络图\",\n",
    "        \"top_header\": \"Top 相关结果\",\n",
    "        \"complete\": \"分析完成！\",\n",
    "        \"summary_data\": \"数据文件\",\n",
    "        \"summary_design\": \"设计规模\",\n",
    "        \"summary_outcomes\": \"结果变量数量\",\n",
    "        \"heatmap_controls\": \"热图控制\",\n",
    "        \"heatmap_colors\": \"热图颜色\",\n",
    "        \"c1\": \"c1（负向，-）\",\n",
    "        \"c3\": \"c3（中性）\",\n",
    "        \"c5\": \"c5（正向，+）\",\n",
    "        \"size\": \"尺寸\",\n",
    "        \"use_explicit\": \"使用固定尺寸\",\n",
    "        \"width_in\": \"宽度（英寸）\",\n",
    "        \"height_in\": \"高度（英寸）\",\n",
    "        \"display\": \"显示\",\n",
    "        \"annotate\": \"显示数值\",\n",
    "        \"center0\": \"以 0 为中心（±vmax）\",\n",
    "        \"xrot\": \"X 轴刻度旋转\",\n",
    "        \"vmax_abs\": \"vmax_abs（可选）\",\n",
    "        \"grid_minor\": \"显示网格\",\n",
    "        \"redraw_heatmap\": \"重绘热图\",\n",
    "        \"save\": \"保存\",\n",
    "        \"filename\": \"文件名\",\n",
    "        \"dpi\": \"DPI\",\n",
    "        \"transparent\": \"透明背景\",\n",
    "        \"save_hm\": \"保存热图 PNG\",\n",
    "        \"net_controls_tip\": \"使用下面的滑块微调网络图布局。\",\n",
    "        \"shown\": \"热图已显示。\",\n",
    "        \"network_tuning\": \"此处微调。\",\n",
    "        \"label_dist\": \"标签间距\",\n",
    "        \"circle_radius\": \"圆半径\",\n",
    "        \"edge_curv\": \"边曲率\",\n",
    "        \"r_thresh\": \"相关阈值 |r|\",\n",
    "        \"top_per_trt\": \"每处理 Top 数\",\n",
    "        \"legend_loc\": \"图例位置\",\n",
    "        \"legend_cols\": \"图例列数\",\n",
    "        \"legend_pad\": \"图例偏移\",\n",
    "        \"title_pad_frac\": \"标题位置（相对）\",\n",
    "        \"redraw\": \"重绘\",\n",
    "        \"save_net\": \"保存网络图 PNG\",\n",
    "        \"drawing_net\": \"正在绘制环形网络图…\",\n",
    "        \"net_title\": \"环形网络图（|r| ≥ {thr}，每处理取前 {k} 个）\",\n",
    "        \"legend_trt\": \"处理\",\n",
    "        \"legend_out\": \"结果\",\n",
    "        \"legend_pos\": \"正相关\",\n",
    "        \"legend_neg\": \"负相关\",\n",
    "        \"colorbar\": \"皮尔逊相关系数\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# add UI labels for font sliders\n",
    "TR[\"en\"].update({\n",
    "    \"tick fs\": \"Tick fontsize\",\n",
    "    \"cell fs\": \"Cell value fontsize\",\n",
    "})\n",
    "TR[\"zh\"].update({\n",
    "    \"tick fs\": \"坐标刻度字体\",\n",
    "    \"cell fs\": \"单元格数字字体\",\n",
    "})\n",
    "\n",
    "\n",
    "def t(key, **kwargs):\n",
    "    return TR.get(LOCALE, TR[\"zh\"]).get(key, key).format(**kwargs)\n",
    "\n",
    "# =============================================================================\n",
    "# 🎨 视觉设置\n",
    "# =============================================================================\n",
    "NETWORK_SETTINGS = {\n",
    "    \"circle_radius\": 1.3,\n",
    "    \"label_distance\": 0.15,\n",
    "    \"figure_size\": (12, 12),\n",
    "    \n",
    "    \"treat_start_deg\": -84.0,   # treatments arc start (default ≈ -90°+0.1rad)\n",
    "    \"treat_end_deg\":    84.0,   # treatments arc end   (default ≈ +90°-0.1rad)\n",
    "    \"out_start_deg\":    96.0,   # outcomes arc start   (default ≈ +90°+0.1rad)\n",
    "    \"out_end_deg\":     264.0,   # outcomes arc end     (default ≈ +270°-0.1rad)\n",
    "\n",
    "    \"treatment_color\": \"#b87430\",\n",
    "    \"outcome_color\":   \"#37b24d\",\n",
    "    \"positive_edge\":   \"#e24a33\",\n",
    "    \"negative_edge\":   \"#2aa198\",\n",
    "    \"background\":      \"white\",\n",
    "\n",
    "    \"node_base_size\": 600,\n",
    "    \"node_size_increment\": 100,\n",
    "\n",
    "    \"edge_base_width\": 1.0,\n",
    "    \"edge_width_scale\": 4.0,\n",
    "    \"edge_alpha\": 0.7,\n",
    "    \"edge_curvature\": 0.3,\n",
    "\n",
    "    \"label_fontsize\": 11,\n",
    "    \"title_fontsize\": 14,\n",
    "    \"legend_fontsize\": 10,\n",
    "\n",
    "    \"show_legend\": True,\n",
    "    \"legend_position\": \"lower center\",\n",
    "    \"legend_anchor\": (0.5, -0.04),\n",
    "    \"legend_ncol\": 2,\n",
    "    \"show_title\": True,\n",
    "    \"legend_pad\": -0.07,\n",
    "    \"title_pad\": 20,\n",
    "    \"title_pad_frac\": -0.05,\n",
    "}\n",
    "\n",
    "HEATMAP_SETTINGS = {\n",
    "    \"figure_size_scale\": 0.6,\n",
    "    \"show_values\": True,\n",
    "    \"tick_fontsize\": 9,   # NEW: axis tick label font size\n",
    "    \"value_fontsize\": 7,  # numbers inside cells\n",
    "    \"colormap\": [\"#01756d\", \"#25c6b8\", \"#e8f9fa\", \"#fed5a9\", \"#fe8e2c\"],\n",
    "}\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    # Explicit names you mentioned\n",
    "    \"WSS\": r\"$C_{WSS}$\",\n",
    "    \"CWSS\": r\"$C_{WSS}$\",\n",
    "    \"CDOM\": r\"$C_{DOM}$\",\n",
    "    \"DOM\": r\"$C_{DOM}$\",\n",
    "    \"HA\": r\"$C_{HA}$\",\n",
    "    \"CHA\": r\"$C_{HA}$\",\n",
    "    \"HE\": r\"$C_{HE}$\",\n",
    "    \"CHE\": r\"$C_{HE}$\",\n",
    "    \"HU\": r\"$C_{Hu}$\",     # note lowercase u\n",
    "    \"CHU\": r\"$C_{Hu}$\",\n",
    "    \"LOGK\": r\"LogK\",\n",
    "    \"LOG K\": r\"LogK\",\n",
    "    \"P\": r\"$\\mathrm{P_{2}O_{5}}$\",\n",
    "    \"K\": r\"$\\mathrm{K_{2}O}$\",\n",
    "    \"E4/E6 of HA\": r\"$E_{4}/E_{6}\\ \\mathrm{(HA)}$\",\n",
    "    \"E4/E6 (HA)\": r\"$E_{4}/E_{6}\\ \\mathrm{(HA)}$\",\n",
    "    \"CHA/CFA\": r\"$C_{HA}/C_{FA}$\",\n",
    "    \"Organic matter\": r\"Organic matter\",\n",
    "    \"Maize yield\": r\"Maize yield\",\n",
    "    \"HIX\": r\"HIX\",\n",
    "}\n",
    "\n",
    "import re\n",
    "KNOWN_C_SUFFIXES = {\"WSS\",\"DOM\",\"HA\",\"HE\",\"HU\",\"FA\"}  # extend if needed\n",
    "\n",
    "def latex_label(name: str) -> str:\n",
    "    s = str(name).strip()\n",
    "    if s in LABEL_MAP:\n",
    "        return LABEL_MAP[s]\n",
    "\n",
    "    u = s.upper().replace(\" \", \"\")\n",
    "    # Auto-map C+suffix (CWSS, CHE, CHU, etc.) → C_{...}\n",
    "    m = re.fullmatch(r\"C([A-Z]+)\", u)\n",
    "    if m and m.group(1) in KNOWN_C_SUFFIXES:\n",
    "        suf = m.group(1)\n",
    "        if suf == \"HU\":\n",
    "            return r\"$C_{Hu}$\"    # keep lowercase u\n",
    "        return rf\"$C_{{{suf}}}$\"\n",
    "\n",
    "    # Bare suffix (WSS, HE, HU, DOM, HA, FA) → assume C_{...}\n",
    "    if u in KNOWN_C_SUFFIXES:\n",
    "        if u == \"HU\":\n",
    "            return r\"$C_{Hu}$\"\n",
    "        return rf\"$C_{{{u}}}$\"\n",
    "\n",
    "    # Tolerate spacing in LOG K\n",
    "    if u == \"LOGK\":\n",
    "        return r\"LogK\"\n",
    "\n",
    "    # (Optional) normalize simple E4/E6 patterns\n",
    "    if re.fullmatch(r\"E4/?E6(?:OFHA|\\(HA\\))?\", u):\n",
    "        return r\"$E_{4}/E_{6}\\ \\mathrm{(HA)}$\"\n",
    "\n",
    "    # Default: unchanged\n",
    "    return s\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "import os, time, warnings, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.lines import Line2D\n",
    "import networkx as nx\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def _running_in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        return get_ipython().__class__.__name__ == \"ZMQInteractiveShell\"\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if _running_in_notebook():\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# =============================================================================\n",
    "# 示例格式（中文）\n",
    "# =============================================================================\n",
    "# —— 简洁中文上传指南（Zn 版本，打印用）——\n",
    "TR[\"zh\"].update({\n",
    "    \"sample_title\": \"上传前请按下述英文表头整理（仅 ASCII），示例：\",\n",
    "    \"legend_block\": (\n",
    "        \"上传规范：\\n\"\n",
    "        \"- 第一列表头必须为 index；行值仅能是 Zn0、LZn、HZn（锌的 3 个水平）。\\n\"\n",
    "        \"- 其它列为数值型结果变量（英文/数字/下划线，勿用中文或全角字符）。\\n\"\n",
    "        \"- 小数使用点号 .（如 7.83），不要逗号。\\n\"\n",
    "        \"- 可自行增删结果列；顺序不限。\\n\"\n",
    "        \"- 保存为 .xlsx/.xls 后上传。\"\n",
    "    )\n",
    "})\n",
    "\n",
    "SAMPLE_FORMAT = f\"\"\"\n",
    "{t('sample_title')}\n",
    "\n",
    "index | AlkaliN | AvailP | AvailK | SOM  | pH  | AvailZn | Yield\n",
    "------+---------+--------+--------+------+-----+---------+-------\n",
    "Zn0   |  98.4   |  19.4  |  172.4 | 14.8 | 6.11|  6.74   | 10257.1\n",
    "LZn   |  65.7   |  33.0  |  189.7 | 15.0 | 5.34|  7.96   | 12426.8\n",
    "HZn   |  85.5   |  20.7  |  176.7 | 13.8 | 5.12|  8.05   | 12522.5\n",
    "\n",
    "{t('legend_block')}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class AutoCorrelationAnalyzer:\n",
    "    def __init__(self, excel_file, title, correlation_threshold, top_k,\n",
    "                 network_settings=None, heatmap_settings=None):\n",
    "        self.data_file = excel_file\n",
    "        self.output_csv = excel_file.replace('.xlsx', '_correlation_results.csv').replace('.xls', '_correlation_results.csv')\n",
    "        self.figure_title = title\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.top_k = top_k\n",
    "        self.network_settings = network_settings or NETWORK_SETTINGS\n",
    "        self.heatmap_settings = heatmap_settings or HEATMAP_SETTINGS\n",
    "        self.color_scheme = self.heatmap_settings.get(\"colormap\",\n",
    "                            [\"#01756d\", \"#25c6b8\", \"#e8f9fa\", \"#fed5a9\", \"#fe8e2c\"])\n",
    "        # Fonts: keep plots strictly in Times New Roman\n",
    "        mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "        mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "        mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "        mpl.rcParams['figure.constrained_layout.use'] = False\n",
    "\n",
    "\n",
    "        self.df = None\n",
    "        self.material_cols = None\n",
    "        self.additive_cols = None\n",
    "        self.outcome_cols = None\n",
    "        self.design_matrix = None\n",
    "        self.correlation_matrix = None\n",
    "        self._last_heatmap = None\n",
    "        self._last_network = None\n",
    "\n",
    "    def _pretty(self, name: str) -> str:\n",
    "        return latex_label(name)\n",
    "\n",
    "\n",
    "    def check_file_exists(self):\n",
    "        if not os.path.exists(self.data_file):\n",
    "            print(f\"\\n❌ {t('cant_find')} '{self.data_file}'\")\n",
    "            print(f\"\\n📁 {t('current_folder')}: {os.getcwd()}\")\n",
    "            print(f\"   {t('excel_here')}: {[f for f in os.listdir('.') if f.endswith(('.xlsx', '.xls'))]}\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def _ask_levels_interactively(self, s: pd.Series, uniq: list, default_order: list):\n",
    "        \"\"\"\n",
    "        交互式让用户确认是否采用“单因子梯度”，并按顺序输入水平。\n",
    "        s: 规范化后的 index 序列\n",
    "        uniq: 唯一标签列表\n",
    "        default_order: 自动推断的默认顺序\n",
    "        返回：pd.Series（类别型，带顺序）或 None（不使用梯度模式）\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\n🔎 检测到可能的单因子标签：\", \", \".join(map(str, default_order)))\n",
    "            use = input(\"是否启用【单因子梯度】模式？(y/N)：\").strip().lower()\n",
    "        except Exception:\n",
    "            use = \"n\"\n",
    "\n",
    "        if use != \"y\":\n",
    "            return None\n",
    "\n",
    "        # 询问元素名称（可为空）\n",
    "        try:\n",
    "            hint = input(\"请输入元素名称/前缀（如 Zn/Cu；直接回车跳过）：\").strip()\n",
    "            if hint:\n",
    "                # 动态更新全局提示，便于后续保存或再次运行\n",
    "                globals()[\"FACTOR_HINT\"] = hint\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # 询问水平个数（默认=唯一标签数）\n",
    "        try:\n",
    "            n_default = len(default_order)\n",
    "            n = input(f\"共有几个水平？(默认 {n_default})：\").strip()\n",
    "            n = int(n) if n else n_default\n",
    "        except Exception:\n",
    "            n = len(default_order)\n",
    "\n",
    "        # 逐项输入顺序（共 n 次），回车采用默认\n",
    "        chosen = []\n",
    "        for i in range(n):\n",
    "            d = default_order[i] if i < len(default_order) else (default_order[-1] if default_order else \"\")\n",
    "            try:\n",
    "                val = input(f\"第 {i+1} 个水平名称（回车采用默认 {d}）：\").strip() or str(d)\n",
    "            except Exception:\n",
    "                val = str(d)\n",
    "            chosen.append(val)\n",
    "\n",
    "        # 仅保留数据中真实存在的水平，避免写错导致全空\n",
    "        exist = set(map(str, uniq))\n",
    "        final_order = [x for x in chosen if x in exist]\n",
    "        if not final_order:               # 全都不在数据里，退回默认\n",
    "            final_order = [x for x in default_order if x in exist] or list(exist)\n",
    "\n",
    "        print(\"✅ 使用顺序：\", \" < \" .join(final_order))\n",
    "        return pd.Categorical(s, categories=final_order, ordered=True).astype(str)\n",
    "\n",
    "    \n",
    "    def _maybe_single_factor_from_index(self, labels, factor_hint=None):\n",
    "        \"\"\"\n",
    "        labels: pd.Series[str]（已标准化的 index 列）\n",
    "        返回：pd.Series[str] 的 Treatment（按有序分类排好序），或 None 表示不适用\n",
    "        \"\"\"\n",
    "        s = labels.fillna(\"\").astype(str).str.strip()\n",
    "        if s.eq(\"\").all():\n",
    "            return None\n",
    "\n",
    "        # 若像 I-/II- 这种组合很多，交给旧逻辑\n",
    "        if (s.str.contains(r\"\\bI{1,3}\\s*[-—－]\").mean() > 0.4) or (s.str.contains(r\"-\").mean() > 0.6):\n",
    "            return None\n",
    "\n",
    "        # 有前缀提示（如 'Zn'/'Cu'），优先用“前缀+数字”抽取并按数值排序\n",
    "        if factor_hint:\n",
    "            import re\n",
    "            pat = re.compile(rf\"^{re.escape(factor_hint)}[\\s_:-]*([+-]?\\d+(?:\\.\\d+)?)\", re.I)\n",
    "            num = s.str.extract(pat, expand=False)\n",
    "            if num.notna().any():\n",
    "                vals = pd.to_numeric(num, errors=\"coerce\")\n",
    "                order = (pd.Series(vals).groupby(s, sort=False).mean().sort_values(kind=\"mergesort\"))\n",
    "                cats = list(order.index)\n",
    "                # 🆕 先给用户机会自定义顺序\n",
    "                if INTERACTIVE_LEVEL_PROMPT:\n",
    "                    asked = self._ask_levels_interactively(s, uniq=list(pd.unique(s)), default_order=cats)\n",
    "                    if asked is not None:\n",
    "                        return asked\n",
    "                return pd.Categorical(s, categories=cats, ordered=True).astype(str)\n",
    "\n",
    "        # 无提示：自动类别化（上限 MAX_LEVELS）\n",
    "        uniq = list(pd.unique(s))\n",
    "        if len(uniq) == 0 or len(uniq) > MAX_LEVELS:\n",
    "            return None\n",
    "\n",
    "        # 能提取到数字就按数字；否则按字母\n",
    "        nums = pd.to_numeric(s.str.extract(r\"([+-]?\\d+(?:\\.\\d+)?)\", expand=False), errors=\"coerce\")\n",
    "        if nums.notna().sum() >= len(uniq) // 2:\n",
    "            key = nums.groupby(s, sort=False).mean().sort_values(kind=\"mergesort\")\n",
    "            cat_order = list(key.index)\n",
    "        else:\n",
    "            cat_order = sorted(set(uniq), key=lambda x: (x.lower(), x))\n",
    "\n",
    "        # 若给了 LEVEL_ORDER，优先用\n",
    "        if LEVEL_ORDER:\n",
    "            pref = [c for c in LEVEL_ORDER if c in set(uniq)]\n",
    "            others = [c for c in cat_order if c not in set(pref)]\n",
    "            cat_order = pref + others\n",
    "\n",
    "        # 🆕 交互式逐项确认（会问 len 水平次）\n",
    "        if INTERACTIVE_LEVEL_PROMPT:\n",
    "            asked = self._ask_levels_interactively(s, uniq=uniq, default_order=cat_order)\n",
    "            if asked is not None:\n",
    "                return asked\n",
    "\n",
    "        return pd.Categorical(s, categories=cat_order, ordered=True).astype(str)\n",
    "\n",
    "\n",
    "\n",
    "    # --- Build design from labels like I-CK ---\n",
    "    def _derive_design_from_index(self) -> bool:\n",
    "        \n",
    "        # in _derive_design_from_index()\n",
    "        cand = [c for c in self.df.columns\n",
    "                if str(c).strip().lower() in (\"index\",\"treatment\",\"treatments\",\"group\",\"sample\")]\n",
    "        idx_col = cand[0] if cand else None\n",
    "        # after: idx_col = ... (once it's known)\n",
    "        self.df = self.df.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "        for c in self.df.columns:\n",
    "            if c != idx_col:\n",
    "                self.df[c] = pd.to_numeric(self.df[c], errors=\"coerce\")\n",
    "\n",
    "        \n",
    "        \n",
    "        if idx_col is None:\n",
    "            c0 = self.df.columns[0]\n",
    "            if not pd.api.types.is_object_dtype(self.df[c0]):\n",
    "                return False\n",
    "            idx_col = c0\n",
    "\n",
    "        roman_map = {\"Ⅰ\":\"I\",\"Ⅱ\":\"II\",\"Ⅲ\":\"III\",\"Ⅳ\":\"IV\",\"Ⅴ\":\"V\",\"Ⅵ\":\"VI\",\"Ⅶ\":\"VII\",\"Ⅷ\":\"VIII\",\"Ⅸ\":\"IX\",\"Ⅹ\":\"X\",\n",
    "                     \"ⅰ\":\"I\",\"ⅱ\":\"II\",\"ⅲ\":\"III\",\"ⅳ\":\"IV\",\"ⅴ\":\"V\",\"ⅵ\":\"VI\",\"ⅶ\":\"VII\",\"ⅷ\":\"VIII\",\"ⅸ\":\"IX\",\"ⅹ\":\"X\"}\n",
    "        def _norm(s: str) -> str:\n",
    "            s = str(s)\n",
    "            for k,v in roman_map.items():\n",
    "                s = s.replace(k, v)\n",
    "            s = s.replace(\"–\",\"-\").replace(\"—\",\"-\").replace(\"−\",\"-\")\n",
    "            s = re.sub(r\"\\s*-\\s*\", \"-\", s)\n",
    "            return s.strip()\n",
    "\n",
    "        labels = self.df[idx_col].astype(str).map(_norm)\n",
    "        # ===== 单因子“梯度”通用识别（任意元素/任意水平）=====\n",
    "\n",
    "        treat_series = self._maybe_single_factor_from_index(labels, factor_hint=FACTOR_HINT)\n",
    "        if treat_series is not None:\n",
    "            self.df[\"Treatment\"] = treat_series\n",
    "            self.material_cols = []       # 单因子模式不用材料/添加剂\n",
    "            self.additive_cols = []\n",
    "            self._index_label_col = idx_col\n",
    "            print(\"\\n🧩 检测到单因子梯度设计：\", list(pd.Categorical(treat_series).categories))\n",
    "            return True\n",
    "\n",
    "\n",
    "        parts = labels.str.extract(r\"^\\s*([A-Za-z]+|[IVX]+)\\s*-\\s*(.*)$\", expand=True)\n",
    "        if parts.isna().any().any():\n",
    "            return False\n",
    "\n",
    "        head = parts[0].str.upper().str.strip()\n",
    "        tail = parts[1].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "        if not {\"I\",\"II\"} & set(head.unique()):\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            name_I  = input(t(\"ask_I\", default_I=\"SMS\")).strip() or \"SMS\"\n",
    "            name_II = input(t(\"ask_II\", default_II=\"PM\")).strip()  or \"PM\"\n",
    "        except Exception:\n",
    "            name_I, name_II = \"SMS\", \"PM\"\n",
    "\n",
    "        for col in [name_I, name_II, \"CK\", \"Cat\", \"Glu\", \"Gly\"]:\n",
    "            if col not in self.df.columns:\n",
    "                self.df[col] = 0\n",
    "\n",
    "        self.df.loc[head==\"I\",  name_I]  = 1\n",
    "        self.df.loc[head==\"II\", name_II] = 1\n",
    "\n",
    "        def _map_add(tok: str):\n",
    "            t0 = str(tok).strip().lower()\n",
    "            if t0 in (\"ck\",\"control\",\"ctrl\"): return \"CK\"\n",
    "            if t0.startswith(\"cat\"): return \"Cat\"\n",
    "            if t0.startswith(\"glu\"): return \"Glu\"\n",
    "            if t0.startswith(\"gly\"): return \"Gly\"\n",
    "            return None\n",
    "\n",
    "        for i, s in tail.items():\n",
    "            if not s:\n",
    "                self.df.at[i, \"CK\"] = 1\n",
    "                continue\n",
    "            tokens = [p for p in re.split(r\"[+,&/ ]+\", s) if p]\n",
    "            matched = False\n",
    "            for tok in tokens:\n",
    "                col = _map_add(tok)\n",
    "                if col:\n",
    "                    self.df.at[i, col] = 1; matched = True\n",
    "            if not matched:\n",
    "                self.df.at[i, \"CK\"] = 1\n",
    "\n",
    "        self.material_cols = [name_I, name_II]\n",
    "        add_candidates = [\"CK\",\"Cat\",\"Glu\",\"Gly\"]\n",
    "        self.additive_cols = [c for c in add_candidates if self.df[c].sum() > 0] or [\"CK\"]\n",
    "        self._index_label_col = idx_col\n",
    "\n",
    "        print(\"\\n🧩 \" + t(\"built_from_index\"))\n",
    "        print(f\"  {t('materials')}: {self.material_cols}\")\n",
    "        print(f\"  {t('additives')}: {self.additive_cols}\")\n",
    "        return True\n",
    "\n",
    "    def load_and_detect(self):\n",
    "        if not self.check_file_exists(): return None\n",
    "        try:\n",
    "            self.df = pd.read_excel(self.data_file)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ {e}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"\\n✅ {t('loaded_rows', n=len(self.df))} '{self.data_file}'\")\n",
    "        print(\"\\n🧹 \" + t(\"cleaning\"))\n",
    "        self._clean_column_names()\n",
    "\n",
    "        if self._derive_design_from_index():\n",
    "            non_outcome = set(self.material_cols + self.additive_cols)\n",
    "            non_outcome.add(getattr(self, \"_index_label_col\", \"\"))\n",
    "            self.outcome_cols = [c for c in self.df.columns\n",
    "                                 if c not in non_outcome and pd.api.types.is_numeric_dtype(self.df[c])]\n",
    "            print(\"\\n🔍 \" + t(\"auto_detected\"))\n",
    "            print(f\"  📦 {t('materials')}: {self.material_cols}\")\n",
    "            print(f\"  🧪 {t('additives')}: {self.additive_cols}\")\n",
    "            print(f\"  📊 {t('outcomes')}: {self.outcome_cols[:5]}{' ...' if len(self.outcome_cols)>5 else ''}\")\n",
    "            if not self.outcome_cols:\n",
    "                print(\"\\n❌ \" + t(\"no_numeric\")); return None\n",
    "            return self\n",
    "\n",
    "        # fallback (unchanged logic, Chinese prints)\n",
    "        all_cols = list(self.df.columns); start_idx = 0\n",
    "        if 'index' in [c.lower() for c in all_cols[:2]]: start_idx = 1\n",
    "        elif all_cols and str(all_cols[0]).startswith('Unnamed'): start_idx = 1\n",
    "\n",
    "        binary_cols, numeric_cols = [], []\n",
    "        for col in all_cols[start_idx:]:\n",
    "            if pd.api.types.is_numeric_dtype(self.df[col]):\n",
    "                vals = set(self.df[col].dropna().unique())\n",
    "                (binary_cols if vals.issubset({0,1,0.0,1.0}) else numeric_cols).append(col)\n",
    "\n",
    "        if len(binary_cols) >= 2:\n",
    "            self.material_cols = binary_cols[:2]; self.additive_cols = binary_cols[2:6]\n",
    "        else:\n",
    "            self.material_cols = all_cols[start_idx:start_idx+2]\n",
    "            self.additive_cols = all_cols[start_idx+2:start_idx+6]\n",
    "\n",
    "        self.outcome_cols = [c for c in numeric_cols if c not in (self.material_cols + self.additive_cols)]\n",
    "\n",
    "        print(\"\\n🔍 \" + t(\"fallback_detected\"))\n",
    "        print(f\"  📦 {t('materials')}: {self.material_cols}\")\n",
    "        print(f\"  🧪 {t('additives')}: {self.additive_cols}\")\n",
    "        print(f\"  📊 {t('outcomes')}: {self.outcome_cols[:5]}{' ...' if len(self.outcome_cols)>5 else ''}\")\n",
    "        if not self.outcome_cols:\n",
    "            print(\"\\n❌ \" + t(\"no_numeric\")); return None\n",
    "        return self\n",
    "\n",
    "    def _clean_column_names(self):\n",
    "        cols_to_drop = []\n",
    "        for col in self.df.columns:\n",
    "            s = str(col)\n",
    "            if any(p in s for p in ['(a+b+c)/d', '（a+b+c)/d', 'a+b+c', 'a＋b＋c']):\n",
    "                cols_to_drop.append(col)\n",
    "        if cols_to_drop:\n",
    "            self.df = self.df.drop(columns=cols_to_drop)\n",
    "            print(f\"  {t('removed_cols', n=len(cols_to_drop))}\")\n",
    "\n",
    "        repl = {'（': '(', '）': ')', '△': 'Δ', '／': '/', '：': ':',\n",
    "                '，': ',', '。': '.', '＋': '+', '－': '-', '×': 'x'}\n",
    "        clean_cols = []\n",
    "        for col in self.df.columns:\n",
    "            t0 = str(col)\n",
    "            for a,b in repl.items():\n",
    "                t0 = t0.replace(a,b)\n",
    "            t0 = ''.join(ch if ord(ch)<128 else '_' for ch in t0)\n",
    "            clean_cols.append(t0)\n",
    "        self.df.columns = clean_cols\n",
    "\n",
    "    def create_treatment_labels(self):\n",
    "        def _get_material_label(row):\n",
    "            if not self.material_cols: return \"Unknown\"\n",
    "            act = [c for c in self.material_cols if row.get(c,0)>0]\n",
    "            return \"+\".join(act) if act else \"No-material\"\n",
    "\n",
    "        def _get_additive_label(row):\n",
    "            if not self.additive_cols: return \"None\"\n",
    "            for c in self.additive_cols:\n",
    "                if 'ck' in c.lower() and row.get(c,0)>0:\n",
    "                    return \"Control\"\n",
    "            act = [c for c in self.additive_cols if 'ck' not in c.lower() and row.get(c,0)>0]\n",
    "            return \"+\".join(act) if act else \"Control\"\n",
    "\n",
    "        labels = []\n",
    "        for _, row in self.df.iterrows():\n",
    "            labels.append(f\"{_get_material_label(row)} + {_get_additive_label(row)}\")\n",
    "        self.df['Treatment'] = labels\n",
    "\n",
    "        uni = sorted(set(labels))\n",
    "        print(f\"\\n📊 {t('found_treatments', k=len(uni))}\")\n",
    "        for i, tt in enumerate(uni, 1):\n",
    "            print(f\"   {i:2d}. {tt:<40} (n={(self.df['Treatment']==tt).sum()})\")\n",
    "        return uni\n",
    "\n",
    "    def prepare_design_matrix(self):\n",
    "        # 如果已经有 Treatment 列（例如 Zn 模式），直接用它\n",
    "        if \"Treatment\" in self.df.columns:\n",
    "            treatments = list(pd.Categorical(self.df[\"Treatment\"]).categories)\n",
    "            if not treatments:  # 兜底\n",
    "                treatments = sorted(self.df[\"Treatment\"].unique())\n",
    "        else:\n",
    "            treatments = self.create_treatment_labels()\n",
    "\n",
    "        design = {t_: (self.df[\"Treatment\"] == t_).astype(int) for t_ in treatments}\n",
    "        self.design_matrix = pd.DataFrame(design, index=self.df.index)\n",
    "        print(f\"\\n✅ {t('design_shape', n=self.design_matrix.shape[0], p=self.design_matrix.shape[1])}\")\n",
    "        return self\n",
    "\n",
    "\n",
    "    def calculate_correlations(self):\n",
    "        print(f\"\\n📈 {t('calc_corr', m=len(self.outcome_cols))}\")\n",
    "        X = self.df[self.outcome_cols].copy()\n",
    "        corr = pd.concat([self.design_matrix, X], axis=1).corr(method='pearson')\n",
    "        self.correlation_matrix = corr.loc[self.design_matrix.columns, self.outcome_cols].copy()\n",
    "        print(\"✅ \" + t(\"calc_done\"))\n",
    "        return self\n",
    "\n",
    "    def save_results(self):\n",
    "        with open(self.output_csv, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# Correlation Analysis Results / 相关性分析结果\\n\")\n",
    "            f.write(f\"# Data file / 数据文件: {self.data_file}\\n\")\n",
    "            f.write(f\"# {t('materials')}: {', '.join(self.material_cols)}\\n\")\n",
    "            f.write(f\"# {t('additives')}: {', '.join(self.additive_cols)}\\n\")\n",
    "            f.write(f\"# {t('outcomes')}: {len(self.outcome_cols)}\\n#\\n\")\n",
    "        self.correlation_matrix.to_csv(self.output_csv, mode='a', encoding='utf-8')\n",
    "        print(f\"\\n💾 {t('saved_to')} : {self.output_csv}\")\n",
    "        return self\n",
    "\n",
    "    def plot_heatmap(self):\n",
    "        # 1) Guard: matrix must exist and be non-empty\n",
    "        if self.correlation_matrix is None or self.correlation_matrix.empty:\n",
    "            # try to compute once if missing\n",
    "            try:\n",
    "                if self.design_matrix is not None and self.outcome_cols:\n",
    "                    self.calculate_correlations()\n",
    "            except Exception:\n",
    "                pass\n",
    "        if self.correlation_matrix is None or self.correlation_matrix.empty:\n",
    "            print(\"⚠️ 无可绘制的相关矩阵（为空或尚未计算）。\")\n",
    "            return\n",
    "\n",
    "        print(\"\\n🎨 \" + t(\"hm_creating\"))\n",
    "        s = self.heatmap_settings or {}\n",
    "\n",
    "        # 2) Safe rows/cols\n",
    "        rows = list(self.correlation_matrix.index)\n",
    "        cols = list(self.correlation_matrix.columns)\n",
    "\n",
    "        # 3) Safe colormap\n",
    "        default_cm = [\"#01756d\", \"#25c6b8\", \"#e8f9fa\", \"#fed5a9\", \"#fe8e2c\"]\n",
    "        colors = s.get(\"colormap\")\n",
    "        if not isinstance(colors, (list, tuple)) or len(colors) < 2:\n",
    "            colors = default_cm[:]\n",
    "        # normalize to exactly 5 anchors\n",
    "        if len(colors) < 5:\n",
    "            colors = (colors + [colors[-1]])[:5] if colors else default_cm[:]\n",
    "            while len(colors) < 5:\n",
    "                colors = [colors[0]] + colors + [colors[-1]]\n",
    "                colors = colors[:5]\n",
    "        elif len(colors) > 5:\n",
    "            colors = [colors[0], colors[1], colors[len(colors)//2], colors[-2], colors[-1]]\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom5\", colors, N=256)\n",
    "\n",
    "        # 4) Safe figure size\n",
    "        fig_w = fig_h = None\n",
    "        fs = s.get(\"figure_size\", None)\n",
    "        if isinstance(fs, (list, tuple)) and len(fs) >= 2:\n",
    "            try:\n",
    "                fig_w, fig_h = float(fs[0]), float(fs[1])\n",
    "            except Exception:\n",
    "                fig_w = fig_h = None\n",
    "        if fig_w is None or fig_h is None:\n",
    "            scale = s.get(\"figure_size_scale\", 0.6) or 0.6\n",
    "            try:\n",
    "                scale = float(scale)\n",
    "            except Exception:\n",
    "                scale = 0.6\n",
    "            # make sure len(...) never gets 0\n",
    "            ncols = max(1, len(cols))\n",
    "            nrows = max(1, len(rows))\n",
    "            fig_w = max(8.0, ncols * scale)\n",
    "            fig_h = max(4.0, nrows * scale)\n",
    "\n",
    "        # 5) Safe limits / options\n",
    "        vcenter_zero = bool(s.get(\"vcenter_zero\", True))\n",
    "        vmax_abs = s.get(\"vmax_abs\", None)\n",
    "        try:\n",
    "            vmax_abs = float(vmax_abs)\n",
    "            if vmax_abs <= 0:\n",
    "                vmax_abs = None\n",
    "        except (TypeError, ValueError):\n",
    "            vmax_abs = None\n",
    "\n",
    "        data = self.correlation_matrix.values.astype(float)\n",
    "        absm = np.nanmax(np.abs(data)) if vmax_abs is None else float(vmax_abs)\n",
    "        if not np.isfinite(absm) or absm == 0:\n",
    "            absm = 1e-6\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "        if vcenter_zero:\n",
    "            norm = TwoSlopeNorm(vmin=-absm, vcenter=0.0, vmax=absm)\n",
    "            im = ax.imshow(data, aspect='auto', cmap=cmap, norm=norm)\n",
    "        else:\n",
    "            im = ax.imshow(data, aspect='auto', cmap=cmap, vmin=-absm, vmax=absm)\n",
    "\n",
    "        ax.set_xticks(np.arange(len(cols)))\n",
    "        rot = s.get(\"rotate_xticks\", 45)\n",
    "        try:\n",
    "            rot = float(rot)\n",
    "        except Exception:\n",
    "            rot = 45.0\n",
    "        ax.set_xticklabels(\n",
    "            [self._pretty(c) for c in cols],\n",
    "            rotation=rot, ha='right',\n",
    "            fontsize=int(s.get(\"tick_fontsize\", 9))  # <<< NEW\n",
    "        )\n",
    "\n",
    "        ax.set_yticks(np.arange(len(rows)))\n",
    "        ax.set_yticklabels(rows, fontsize=int(s.get(\"tick_fontsize\", 9))) \n",
    "        ax.set_title(self.figure_title, fontsize=s.get(\"title_fontsize\", 14), fontweight='bold', pad=20)\n",
    "\n",
    "        # annotations\n",
    "        if bool(s.get(\"annotate\", s.get(\"show_values\", True))):\n",
    "            val_fs = int(s.get(\"value_fontsize\", 7) or 7)\n",
    "            cap = absm\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    val = data[i, j]\n",
    "                    if np.isfinite(val):\n",
    "                        mag = abs(val)/(cap+1e-12)\n",
    "                        color = 'white' if mag>0.6 else 'black' if mag>0.4 else '#333333'\n",
    "                        ax.text(j, i, f'{val:.2f}', ha=\"center\", va=\"center\",\n",
    "                                fontsize=val_fs, fontweight='bold', color=color)\n",
    "\n",
    "        cbar = plt.colorbar(im, ax=ax, shrink=0.85)\n",
    "        cbar.ax.set_ylabel(t_plot(\"colorbar\"), rotation=90)\n",
    "\n",
    "        if bool(s.get(\"grid_minor\", True)):\n",
    "            ax.set_xticks(np.arange(len(cols)+1)-0.5, minor=True)\n",
    "            ax.set_yticks(np.arange(len(rows)+1)-0.5, minor=True)\n",
    "            ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.3, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"✅ \" + t(\"hm_done\"))\n",
    "        self._last_heatmap = (fig, ax)\n",
    "        return fig, ax\n",
    "\n",
    "\n",
    "    def _legend_anchor_from_pad(self, loc: str, pad: float):\n",
    "        loc = (loc or \"\").lower()\n",
    "        if loc == \"lower center\": return (0.5, -pad)\n",
    "        if loc == \"upper center\": return (0.5, 1 + pad)\n",
    "        if loc == \"center left\":  return (-pad, 0.5)\n",
    "        if loc == \"center right\": return (1 + pad, 0.5)\n",
    "        if loc == \"lower left\":   return (-pad, -pad)\n",
    "        if loc == \"lower right\":  return (1 + pad, -pad)\n",
    "        if loc == \"upper left\":   return (-pad, 1 + pad)\n",
    "        if loc == \"upper right\":  return (1 + pad, 1 + pad)\n",
    "        return None\n",
    "\n",
    "    def plot_pie_network(self):\n",
    "        if self.correlation_matrix is None: return\n",
    "        print(\"\\n🎨 \" + t(\"net_creating\"))\n",
    "        s = self.network_settings\n",
    "\n",
    "        G = nx.Graph()\n",
    "        treatments = list(self.correlation_matrix.index)\n",
    "        outcomes = list(self.correlation_matrix.columns)\n",
    "        for t0 in treatments: G.add_node(t0, group='treatment')\n",
    "        for o in outcomes:    G.add_node(o, group='outcome')\n",
    "\n",
    "        edges_added = 0\n",
    "        for t0 in treatments:\n",
    "            row = self.correlation_matrix.loc[t0].dropna()\n",
    "            row_abs = row.abs().sort_values(ascending=False)\n",
    "            count = 0\n",
    "            for o, abs_r in row_abs.items():\n",
    "                if abs_r >= self.correlation_threshold and count < self.top_k:\n",
    "                    r = row[o]\n",
    "                    G.add_edge(t0, o, weight=abs_r, correlation=r)\n",
    "                    edges_added += 1; count += 1\n",
    "        if edges_added == 0:\n",
    "            print(\"⚠ \" + t(\"no_edges\", thr=self.correlation_threshold)); return None\n",
    "\n",
    "        radius = s[\"circle_radius\"]; fig_size = s[\"figure_size\"]\n",
    "        fig, ax = plt.subplots(figsize=fig_size, constrained_layout=False)\n",
    "        if s.get(\"background\") != \"white\":\n",
    "            fig.patch.set_facecolor(s[\"background\"]); ax.set_facecolor(s[\"background\"])\n",
    "\n",
    "        pos = {}\n",
    "        n_t = len(treatments)\n",
    "        def _arc_linspace_deg(start_deg, end_deg, n):\n",
    "            sdeg = float(s.get(start_deg, -84.0))\n",
    "            edeg = float(s.get(end_deg,  84.0))\n",
    "            # allow wrapping if user drags start past end\n",
    "            if sdeg >= edeg:\n",
    "                edeg += 360.0\n",
    "            return np.deg2rad(np.linspace(sdeg, edeg, n, endpoint=True))\n",
    "\n",
    "        theta_t = _arc_linspace_deg(\"treat_start_deg\", \"treat_end_deg\", n_t)\n",
    "        for i, t0 in enumerate(treatments):\n",
    "            pos[t0] = (radius*np.cos(theta_t[i]), radius*np.sin(theta_t[i]))\n",
    "\n",
    "        outcome_scores = []\n",
    "        for o in outcomes:\n",
    "            ang, w = [], []\n",
    "            for t0 in treatments:\n",
    "                if G.has_edge(t0,o):\n",
    "                    idx = treatments.index(t0)\n",
    "                    ang.append(theta_t[idx]); w.append(G.edges[t0,o]['weight'])\n",
    "            if w:\n",
    "                score = np.arctan2(np.average(np.sin(ang), weights=w),\n",
    "                                   np.average(np.cos(ang), weights=w))\n",
    "            else:\n",
    "                score = np.pi\n",
    "            outcome_scores.append((o, score))\n",
    "        outcome_sorted = [o for o,_ in sorted(outcome_scores, key=lambda x: x[1], reverse=True)]\n",
    "        n_o = len(outcome_sorted)\n",
    "        theta_o = _arc_linspace_deg(\"out_start_deg\", \"out_end_deg\", n_o)\n",
    "        for i, o in enumerate(outcome_sorted):\n",
    "            pos[o] = (radius*np.cos(theta_o[i]), radius*np.sin(theta_o[i]))\n",
    "\n",
    "        for (u,v) in G.edges():\n",
    "            r = G.edges[u,v]['correlation']\n",
    "            color = s[\"positive_edge\"] if r>0 else s[\"negative_edge\"]\n",
    "            width = s[\"edge_base_width\"] + s[\"edge_width_scale\"] * G.edges[u,v]['weight']\n",
    "            ua, va = np.arctan2(pos[u][1], pos[u][0]), np.arctan2(pos[v][1], pos[v][0])\n",
    "            diff = abs(ua - va);  diff = 2*np.pi - diff if diff>np.pi else diff\n",
    "            curv = 0.1 + s[\"edge_curvature\"] * (diff / np.pi)\n",
    "            connectionstyle = f\"arc3,rad={curv if r>0 else -curv}\"\n",
    "            arrow = FancyArrowPatch(pos[u], pos[v], connectionstyle=connectionstyle,\n",
    "                                    arrowstyle='-', color=color, linewidth=width,\n",
    "                                    alpha=s[\"edge_alpha\"], zorder=1)\n",
    "            ax.add_patch(arrow)\n",
    "\n",
    "        node_sizes = {}\n",
    "        for node in G.nodes():\n",
    "            n_conn = len(list(G.edges(node)))\n",
    "            node_sizes[node] = s[\"node_base_size\"] + n_conn * s[\"node_size_increment\"]\n",
    "\n",
    "        for node in G.nodes():\n",
    "            color = s[\"treatment_color\"] if G.nodes[node]['group']=='treatment' else s[\"outcome_color\"]\n",
    "            ax.scatter(pos[node][0], pos[node][1], s=node_sizes[node],\n",
    "                       c=color, edgecolors='white', linewidth=2, zorder=5)\n",
    "\n",
    "        for node in G.nodes():\n",
    "            x, y = pos[node]; r = np.hypot(x, y)\n",
    "            if r > 0:\n",
    "                ux, uy = x/r, y/r\n",
    "                lx, ly = x + s[\"label_distance\"]*ux, y + s[\"label_distance\"]*uy\n",
    "                ha = 'left' if x > 0.1 else 'right' if x < -0.1 else 'center'\n",
    "                display_text = self._pretty(node) if G.nodes[node]['group']=='outcome' else node\n",
    "                ax.text(lx, ly, display_text, fontsize=s[\"label_fontsize\"], ha=ha, va='center')\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        lim = radius + s[\"label_distance\"] + 0.5\n",
    "        ax.set_xlim(-lim, lim); ax.set_ylim(-lim, lim); ax.axis('off')\n",
    "\n",
    "        if s[\"show_title\"]:\n",
    "            ax.text(\n",
    "                0.5, 1.0 + float(s.get(\"title_pad_frac\", -0.05)),\n",
    "                t_plot(\"net_title\", thr=self.correlation_threshold, k=self.top_k),\n",
    "                transform=ax.transAxes, ha='center', va='bottom',\n",
    "                fontsize=s[\"title_fontsize\"], fontweight='bold', zorder=999, clip_on=False\n",
    "            )\n",
    "\n",
    "\n",
    "        if s[\"show_legend\"]:\n",
    "            treatment_marker = Line2D([0],[0], marker='o', color='w',\n",
    "                                      markerfacecolor=s[\"treatment_color\"], markersize=12,\n",
    "                                      markeredgecolor='white', markeredgewidth=1.5,\n",
    "                                      label=t_plot(\"legend_trt\"), linestyle='')\n",
    "            outcome_marker   = Line2D([0],[0], marker='o', color='w',\n",
    "                                      markerfacecolor=s[\"outcome_color\"], markersize=12,\n",
    "                                      markeredgecolor='white', markeredgewidth=1.5,\n",
    "                                      label=t_plot(\"legend_out\"), linestyle='')\n",
    "            pos_line = Line2D([0],[0], color=s[\"positive_edge\"], linewidth=3, label=t_plot(\"legend_pos\"))\n",
    "            neg_line = Line2D([0],[0], color=s[\"negative_edge\"], linewidth=3, label=t_plot(\"legend_neg\"))\n",
    "            legend_elems = [treatment_marker, outcome_marker, pos_line, neg_line]\n",
    "\n",
    "            loc   = s.get(\"legend_position\", \"lower center\")\n",
    "            ncol  = int(s.get(\"legend_ncol\", 1))\n",
    "            pad   = float(s.get(\"legend_pad\", -0.07))\n",
    "            anchor = self._legend_anchor_from_pad(loc, pad)\n",
    "            kw = dict(frameon=False, ncol=ncol, prop={'size': s[\"legend_fontsize\"]})\n",
    "            if anchor is not None:\n",
    "                kw[\"loc\"] = \"center\"; kw[\"bbox_to_anchor\"] = anchor\n",
    "            else:\n",
    "                kw[\"loc\"] = loc\n",
    "            ax.legend(handles=legend_elems, **kw)\n",
    "\n",
    "        plt.show()\n",
    "        print(f\"✅ {t('net_done', E=G.number_of_edges())}\")\n",
    "        self._last_network = (fig, ax)\n",
    "        return fig, ax\n",
    "\n",
    "    def get_significant_correlations(self):\n",
    "        if self.correlation_matrix is None: return None\n",
    "        th = self.correlation_threshold\n",
    "        print(f\"\\n🔍 {t('sig_header', thr=th)}\\n\" + \"-\"*70)\n",
    "        rows = []\n",
    "        for t0 in self.correlation_matrix.index:\n",
    "            for o in self.correlation_matrix.columns:\n",
    "                r = float(self.correlation_matrix.loc[t0,o])\n",
    "                if np.isfinite(r) and abs(r)>th:\n",
    "                    rows.append({\"Treatment\":t0, \"Outcome\":o, \"r\":r, \"abs_r\":abs(r)})\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows).sort_values(\"abs_r\", ascending=False)\n",
    "            for _,row in df.head(20).iterrows():\n",
    "                arrow = \"↑\" if row[\"r\"]>0 else \"↓\"\n",
    "                print(f\"  {row['Treatment']:<30} → {row['Outcome']:<15} r = {row['r']:+.3f} {arrow}\")\n",
    "            if len(df)>20:\n",
    "                print(f\"\\n  ... {len(df)-20} more.\")\n",
    "            return df\n",
    "        else:\n",
    "            print(\"  \" + t(\"none\")); return None\n",
    "\n",
    "    def save_last_figure(self, kind='heatmap', filename=None, dpi=300, transparent=False):\n",
    "        pair = {'heatmap': self._last_heatmap, 'network': self._last_network}.get(kind)\n",
    "        if pair is None:\n",
    "            print(f\"⚠️ No {kind} figure yet.\"); return None\n",
    "        fig, _ = pair\n",
    "        base = os.path.splitext(os.path.basename(self.data_file))[0]\n",
    "        if not filename: filename = f\"{base}_{kind}.png\"\n",
    "        fig.savefig(filename, dpi=int(dpi), bbox_inches='tight', transparent=bool(transparent))\n",
    "        print(f\"💾 {t('saved_to')} : {filename}\")\n",
    "        return filename\n",
    "\n",
    "    def run_full_analysis(self, show_plots: bool = False):\n",
    "        print(\"\\n\" + \"=\"*80); print(f\"   {t('start')}\"); print(\"=\"*80)\n",
    "        if self.load_and_detect() is None:\n",
    "            print(\"\\n❌ \" + t(\"no_numeric\")); return None\n",
    "        self.prepare_design_matrix()\n",
    "        self.calculate_correlations()\n",
    "        self.save_results()\n",
    "\n",
    "        if show_plots:\n",
    "            print(\"\\n\" + \"=\"*80); print(f\"   {t('viz_header')}\"); print(\"=\"*80)\n",
    "            print(\"\\n📊 \" + t(\"viz1\")); self.plot_heatmap()\n",
    "            print(\"\\n📊 \" + t(\"viz2\")); self.plot_pie_network()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80); print(f\"   {t('top_header')}\"); print(\"=\"*80)\n",
    "        self.get_significant_correlations()\n",
    "        print(\"\\n\" + \"=\"*80); print(f\"   ✨ {t('complete')} ✨\"); print(\"=\"*80)\n",
    "        print(f\"\\n 📁 {t('saved_to')} : {self.output_csv}\")\n",
    "        print(f\" 📊 {t('summary_data')}: {self.data_file}\")\n",
    "        print(f\" 🧪 {t('summary_design')}: {len(self.material_cols)} × {len(self.additive_cols)}\")\n",
    "        print(f\" 📈 {t('summary_outcomes')}: {len(self.outcome_cols)}\")\n",
    "        return self\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(t(\"welcome_banner\"))\n",
    "    print(SAMPLE_FORMAT)\n",
    "\n",
    "    print(f\"\\n📂 {t('using_file')}: {MY_EXCEL_FILE}\")\n",
    "    print(f\"🎯 {t('thr')}: {SHOW_CORRELATIONS_ABOVE}\")\n",
    "    print(f\"🔝 {t('topk')}: {TOP_CORRELATIONS_PER_TREATMENT}\")\n",
    "\n",
    "    try:\n",
    "        analyzer = AutoCorrelationAnalyzer(\n",
    "            excel_file=MY_EXCEL_FILE,\n",
    "            title=MY_ANALYSIS_TITLE,\n",
    "            correlation_threshold=SHOW_CORRELATIONS_ABOVE,\n",
    "            top_k=TOP_CORRELATIONS_PER_TREATMENT,\n",
    "            network_settings=NETWORK_SETTINGS,\n",
    "            heatmap_settings=HEATMAP_SETTINGS\n",
    "        )\n",
    "        analyzer.run_full_analysis(show_plots=False)\n",
    "\n",
    "        # ==== Heatmap UI (Chinese labels) ====\n",
    "        if _running_in_notebook():\n",
    "            print(\"\\n🧩 \" + t(\"heatmap_controls\"))\n",
    "            cp_layout = widgets.Layout(width='200px')\n",
    "            cp_style  = {'description_width': '90px'}\n",
    "\n",
    "            c1 = widgets.ColorPicker(value=HEATMAP_SETTINGS[\"colormap\"][0], description=t('c1'),\n",
    "                                     layout=cp_layout, style=cp_style)\n",
    "            c2 = widgets.ColorPicker(value=HEATMAP_SETTINGS[\"colormap\"][1], description='c2',\n",
    "                                     layout=cp_layout, style=cp_style)\n",
    "            c3 = widgets.ColorPicker(value=HEATMAP_SETTINGS[\"colormap\"][2], description=t('c3'),\n",
    "                                     layout=cp_layout, style=cp_style)\n",
    "            c4 = widgets.ColorPicker(value=HEATMAP_SETTINGS[\"colormap\"][3], description='c4',\n",
    "                                     layout=cp_layout, style=cp_style)\n",
    "            c5 = widgets.ColorPicker(value=HEATMAP_SETTINGS[\"colormap\"][4], description=t('c5'),\n",
    "                                     layout=cp_layout, style=cp_style)\n",
    "\n",
    "            hm_w = widgets.FloatSlider(value=12.0, min=6, max=24, step=0.5, description=t('width_in'))\n",
    "            hm_h = widgets.FloatSlider(value=8.0,  min=4, max=24, step=0.5, description=t('height_in'))\n",
    "            use_explicit_size = widgets.Checkbox(value=True, description=t_ui('use_explicit'))\n",
    "\n",
    "            annotate_chk = widgets.Checkbox(value=HEATMAP_SETTINGS.get(\"show_values\", True), description=t_ui('annotate'))\n",
    "            rotate_deg   = widgets.FloatSlider(value=45, min=0, max=90, step=1, description=t('xrot'))\n",
    "            vcenter_zero = widgets.Checkbox(value=True, description=t_ui('center0'))\n",
    "            vmax_abs     = widgets.FloatText(value=None, description=t_ui('vmax_abs'))\n",
    "            grid_minor   = widgets.Checkbox(value=True, description=t_ui('grid_minor'))\n",
    "\n",
    "            redraw_heatmap_btn = widgets.Button(description=t('redraw_heatmap'), button_style='')\n",
    "            out_hm = widgets.Output()\n",
    "\n",
    "            def _redraw_heatmap(_=None):\n",
    "                with out_hm:\n",
    "                    clear_output(wait=True)\n",
    "                    analyzer.heatmap_settings[\"colormap\"] = [c1.value, c2.value, c3.value, c4.value, c5.value]\n",
    "                    analyzer.heatmap_settings[\"rotate_xticks\"] = float(rotate_deg.value)\n",
    "                    analyzer.heatmap_settings[\"annotate\"] = bool(annotate_chk.value)\n",
    "                    analyzer.heatmap_settings[\"show_values\"] = bool(annotate_chk.value)\n",
    "                    analyzer.heatmap_settings[\"vcenter_zero\"] = bool(vcenter_zero.value)\n",
    "                    analyzer.heatmap_settings[\"grid_minor\"] = bool(grid_minor.value)\n",
    "\n",
    "                    # NEW: pass font sizes into settings\n",
    "                    analyzer.heatmap_settings[\"tick_fontsize\"]  = int(tick_fs.value)\n",
    "                    analyzer.heatmap_settings[\"value_fontsize\"] = int(cell_fs.value)\n",
    "\n",
    "                    if use_explicit_size.value:\n",
    "                        analyzer.heatmap_settings[\"figure_size\"] = (float(hm_w.value), float(hm_h.value))\n",
    "                    else:\n",
    "                        analyzer.heatmap_settings[\"figure_size\"] = None\n",
    "\n",
    "                    v = vmax_abs.value\n",
    "                    try: v = float(v)\n",
    "                    except (TypeError, ValueError): v = None\n",
    "                    analyzer.heatmap_settings[\"vmax_abs\"] = None if (v is None or v <= 0) else v\n",
    "\n",
    "                    print(\"🎨 \" + t(\"drawing_hm\"))\n",
    "                    analyzer.plot_heatmap()\n",
    "\n",
    "            redraw_heatmap_btn.on_click(_redraw_heatmap)\n",
    "            save_name_hm = widgets.Text(value='', placeholder='auto name', description=t('filename'))\n",
    "            save_dpi_hm = widgets.IntSlider(value=300, min=72, max=600, step=12, description=t('dpi'))\n",
    "            tick_fs = widgets.IntSlider(\n",
    "                value=int(HEATMAP_SETTINGS.get(\"tick_fontsize\", 9)),\n",
    "                min=6, max=24, step=1, description=t('tick fs')\n",
    "            )\n",
    "            cell_fs = widgets.IntSlider(\n",
    "                value=int(HEATMAP_SETTINGS.get(\"value_fontsize\", 7)),\n",
    "                min=6, max=24, step=1, description=t('cell fs')\n",
    "            )\n",
    "            save_trans_hm = widgets.Checkbox(value=False, description=t('transparent'))\n",
    "            save_heatmap_btn = widgets.Button(description=t('save_hm'), button_style='success')\n",
    "\n",
    "            def _save_heatmap(_=None):\n",
    "                fname = save_name_hm.value.strip() or None\n",
    "                analyzer.save_last_figure('heatmap', filename=fname, dpi=int(save_dpi_hm.value),\n",
    "                                          transparent=bool(save_trans_hm.value))\n",
    "            save_heatmap_btn.on_click(_save_heatmap)\n",
    "\n",
    "            ui_hm = widgets.VBox([\n",
    "                widgets.HTML(f\"<b>{t('heatmap_colors')}</b>\"),\n",
    "                widgets.HBox([c1, c2, c3, c4, c5]),\n",
    "                widgets.HTML(f\"<b>{t('size')}</b>\"),\n",
    "                widgets.HBox([use_explicit_size, hm_w, hm_h]),\n",
    "                widgets.HTML(f\"<b>{t('display')}</b>\"),\n",
    "                widgets.HBox([annotate_chk, grid_minor]),\n",
    "                widgets.HBox([vcenter_zero, rotate_deg, vmax_abs]),\n",
    "                widgets.HBox([tick_fs, cell_fs]),   # <<< NEW row for font sliders\n",
    "                redraw_heatmap_btn,\n",
    "                widgets.HTML(f\"<b>{t('save')}</b>\"),\n",
    "                widgets.HBox([save_name_hm, save_dpi_hm, save_trans_hm]),\n",
    "                save_heatmap_btn\n",
    "            ])\n",
    "\n",
    "            display(ui_hm, out_hm)\n",
    "            if analyzer.correlation_matrix is None or analyzer.correlation_matrix.empty:\n",
    "                analyzer.calculate_correlations()\n",
    "            _redraw_heatmap()\n",
    "\n",
    "        # ==== Network UI (Chinese labels) ====\n",
    "        if _running_in_notebook():\n",
    "            print(\"\\n🎛️ \" + t(\"net_controls_tip\"))\n",
    "            save_name_net = widgets.Text(value='', placeholder='auto name', description=t('filename'))\n",
    "            save_dpi_net = widgets.IntSlider(value=300, min=72, max=600, step=12, description=t('dpi'))\n",
    "            save_trans_net = widgets.Checkbox(value=False, description=t('transparent'))\n",
    "            save_network_btn = widgets.Button(description=t('save_net'), button_style='success')\n",
    "            tr_start = widgets.FloatSlider(\n",
    "                value=analyzer.network_settings.get(\"treat_start_deg\", -84.0),\n",
    "                min=-180, max=180, step=1, description=\"trt start°\", continuous_update=False)\n",
    "            tr_end = widgets.FloatSlider(\n",
    "                value=analyzer.network_settings.get(\"treat_end_deg\", 84.0),\n",
    "                min=-180, max=180, step=1, description=\"trt end°\", continuous_update=False)\n",
    "            out_start = widgets.FloatSlider(\n",
    "                value=analyzer.network_settings.get(\"out_start_deg\", 96.0),\n",
    "                min=-180, max=540, step=1, description=\"out start°\", continuous_update=False)\n",
    "            out_end = widgets.FloatSlider(\n",
    "                value=analyzer.network_settings.get(\"out_end_deg\", 264.0),\n",
    "                min=-180, max=540, step=1, description=\"out end°\", continuous_update=False)\n",
    "\n",
    "            def _save_network(_=None):\n",
    "                fname = save_name_net.value.strip() or None\n",
    "                analyzer.save_last_figure('network', filename=fname, dpi=int(save_dpi_net.value),\n",
    "                                          transparent=bool(save_trans_net.value))\n",
    "            save_network_btn.on_click(_save_network)\n",
    "\n",
    "            if analyzer.correlation_matrix is None:\n",
    "                analyzer.calculate_correlations()\n",
    "\n",
    "            label_slider = widgets.FloatSlider(value=analyzer.network_settings.get(\"label_distance\", 0.15),\n",
    "                                               min=0.02, max=0.80, step=0.01, description=t('label_dist'),\n",
    "                                               continuous_update=False)\n",
    "            radius_slider = widgets.FloatSlider(value=analyzer.network_settings.get(\"circle_radius\", 1.3),\n",
    "                                                min=0.6, max=2.0, step=0.05, description=t('circle_radius'),\n",
    "                                                continuous_update=False)\n",
    "            curve_slider = widgets.FloatSlider(value=analyzer.network_settings.get(\"edge_curvature\", 0.3),\n",
    "                                               min=0.0, max=0.7, step=0.02, description=t('edge_curv'),\n",
    "                                               continuous_update=False)\n",
    "            thresh_slider = widgets.FloatSlider(value=float(analyzer.correlation_threshold),\n",
    "                                                min=0.0, max=0.9, step=0.01, description=t('r_thresh'),\n",
    "                                                continuous_update=False)\n",
    "            topk_slider = widgets.IntSlider(value=int(analyzer.top_k), min=1, max=20, step=1,\n",
    "                                            description=t('top_per_trt'), continuous_update=False)\n",
    "            redraw_btn = widgets.Button(description=t('redraw'), button_style='primary')\n",
    "            out = widgets.Output()\n",
    "\n",
    "            legend_pos_dropdown = widgets.Dropdown(\n",
    "                options=[\"upper left\",\"upper right\",\"lower left\",\"lower right\",\"upper center\",\"lower center\",\n",
    "                         \"center left\",\"center right\",\"center\"],\n",
    "                value=analyzer.network_settings.get(\"legend_position\",\"lower center\"),\n",
    "                description=t('legend_loc'),\n",
    "            )\n",
    "            legend_pad_slider = widgets.FloatSlider(value=float(analyzer.network_settings.get(\"legend_pad\", -0.07)),\n",
    "                                                    min=-0.2, max=0.3, step=0.002,\n",
    "                                                    description=t('legend_pad'), continuous_update=False)\n",
    "            legend_ncol = widgets.IntSlider(value=int(analyzer.network_settings.get(\"legend_ncol\", 2)),\n",
    "                                            min=1, max=4, step=1, description=t('legend_cols'),\n",
    "                                            continuous_update=False)\n",
    "            title_pad_frac_slider = widgets.FloatSlider(\n",
    "                value=float(analyzer.network_settings.get(\"title_pad_frac\", -0.05)),\n",
    "                min=-0.15, max=0.30, step=0.002, description=t('title_pad_frac'), continuous_update=False\n",
    "            )\n",
    "\n",
    "            def _redraw(_=None):\n",
    "                with out:\n",
    "                    clear_output(wait=True)\n",
    "                    analyzer.network_settings[\"label_distance\"] = float(label_slider.value)\n",
    "                    analyzer.network_settings[\"circle_radius\"]  = float(radius_slider.value)\n",
    "                    analyzer.network_settings[\"edge_curvature\"] = float(curve_slider.value)\n",
    "                    analyzer.correlation_threshold              = float(thresh_slider.value)\n",
    "                    analyzer.top_k                               = int(topk_slider.value)\n",
    "                    analyzer.network_settings[\"legend_position\"] = legend_pos_dropdown.value\n",
    "                    analyzer.network_settings[\"legend_ncol\"]     = int(legend_ncol.value)\n",
    "                    analyzer.network_settings[\"legend_pad\"]      = float(legend_pad_slider.value)\n",
    "                    analyzer.network_settings[\"title_pad_frac\"]  = float(title_pad_frac_slider.value)\n",
    "                    analyzer.network_settings[\"treat_start_deg\"] = float(tr_start.value)\n",
    "                    analyzer.network_settings[\"treat_end_deg\"]   = float(tr_end.value)\n",
    "                    analyzer.network_settings[\"out_start_deg\"]   = float(out_start.value)\n",
    "                    analyzer.network_settings[\"out_end_deg\"]     = float(out_end.value)\n",
    "\n",
    "                    print(\"🎨 \" + t(\"drawing_net\"))\n",
    "                    fig_ax = analyzer.plot_pie_network()\n",
    "                    if fig_ax is None:\n",
    "                        print(t(\"no_edges\", thr=analyzer.correlation_threshold))\n",
    "\n",
    "            redraw_btn.on_click(_redraw)\n",
    "            ui = widgets.VBox([\n",
    "                widgets.HBox([label_slider, radius_slider, curve_slider]),\n",
    "                widgets.HBox([tr_start, tr_end, out_start, out_end]),   # ← new angle tuners\n",
    "                widgets.HBox([thresh_slider, topk_slider]),\n",
    "                widgets.HBox([legend_pos_dropdown, legend_ncol, legend_pad_slider]),\n",
    "                widgets.HBox([title_pad_frac_slider]),\n",
    "                redraw_btn,\n",
    "                widgets.HTML(f\"<b>{t('save')}</b>\"),\n",
    "                widgets.HBox([save_name_net, save_dpi_net, save_trans_net]),\n",
    "                save_network_btn\n",
    "            ])\n",
    "\n",
    "            display(ui, out); _redraw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ {e}\")\n",
    "        print(\"\\n💡 常见排查：\\n  1) 确认 Excel 文件存在且可读。\\n  2) 检查文件名/扩展名（.xlsx/.xls）。\\n  3) 二元列应为 0/1，结果列应为数值。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac107c55-5048-4d0e-8a0a-b26d5d810694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
